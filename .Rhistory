#3 es train
cv_data[[3]][[1]][1]
#3 es train
cv_data[[3]][[1]][2]
#3 es train
cv_data[[3]][[1]][3]
cv_data[[3]][[i]].colnames
colnames(cv_data[[3]][[i]])
for (j in 1:5){
aux<-c()
for (i in 1:5){
nombres<-colnames(cv_data[[3]][[i]])
#Entrenamiento
X_train=as.matrix(cv_data[[3]][[i]][j])
Y_train=as.matrix(cv_data[[3]][[i]][6])
#Testeo
X_test=as.matrix(cv_data[[4]][[i]][j])
Y_test=as.matrix(cv_data[[4]][[i]][6])
Ksvm=ksvm(y=as.factor(Y_train),x=X_train,
kernel='vanilladot',scaled=FALSE,C=1)
pred<-predict(Ksvm,X_test)
Table=table(pred,Y_test)
Accuracy=(Table[1,1]+Table[2,2])/sum(Table)
Precision=Table[2,2]/(Table[2,1]+Table[2,2])
Recall=Table[2,2]/(Table[1,2]+Table[2,2])
aux<-cbind(nombres[j],i,Accuracy,Precision,Recall)
lista[[length(lista)+1]]=aux
}
resultados<-cbind("Covariable","Fold","Accuracy","Precision","Recall")
resultados<-rbind(resultados,aux)
return(resultados)
}
View(resultados)
for (j in 1:5){
aux<-c()
for (i in 1:5){
nombres<-colnames(cv_data[[3]][[i]])
#Entrenamiento
X_train=as.matrix(cv_data[[3]][[i]][j])
Y_train=as.matrix(cv_data[[3]][[i]][6])
#Testeo
X_test=as.matrix(cv_data[[4]][[i]][j])
Y_test=as.matrix(cv_data[[4]][[i]][6])
Ksvm=ksvm(y=as.factor(Y_train),x=X_train,
kernel='vanilladot',scaled=FALSE,C=1)
pred<-predict(Ksvm,X_test)
Table=table(pred,Y_test)
Accuracy=(Table[1,1]+Table[2,2])/sum(Table)
Precision=Table[2,2]/(Table[2,1]+Table[2,2])
Recall=Table[2,2]/(Table[1,2]+Table[2,2])
aux<-cbind(aux,nombres[j],i,Accuracy,Precision,Recall)
lista[[length(lista)+1]]=aux
}
resultados<-cbind("Covariable","Fold","Accuracy","Precision","Recall")
resultados<-rbind(resultados,aux)
return(resultados)
}
for (j in 1:5){
aux<-c()
for (i in 1:5){
nombres<-colnames(cv_data[[3]][[i]])
#Entrenamiento
X_train=as.matrix(cv_data[[3]][[i]][j])
Y_train=as.matrix(cv_data[[3]][[i]][6])
#Testeo
X_test=as.matrix(cv_data[[4]][[i]][j])
Y_test=as.matrix(cv_data[[4]][[i]][6])
Ksvm=ksvm(y=as.factor(Y_train),x=X_train,
kernel='vanilladot',scaled=FALSE,C=1)
pred<-predict(Ksvm,X_test)
Table=table(pred,Y_test)
Accuracy=(Table[1,1]+Table[2,2])/sum(Table)
Precision=Table[2,2]/(Table[2,1]+Table[2,2])
Recall=Table[2,2]/(Table[1,2]+Table[2,2])
aux<-cbind(nombres[j],i,Accuracy,Precision,Recall)
aux_2<-rbind(aux_2,aux)
lista[[length(lista)+1]]=aux
}
resultados<-cbind("Covariable","Fold","Accuracy","Precision","Recall")
resultados<-rbind(resultados,aux_2)
return(resultados)
}
View(folds)
View(cv_data)
View(cv_data[[3]][[1]])
for (j in 1:5){
nombres<-colnames(cv_data[[3]][[1]])
aux<-c()
for (i in 1:5){
#Entrenamiento
X_train=as.matrix(cv_data[[3]][[i]][j])
Y_train=as.matrix(cv_data[[3]][[i]][6])
#Testeo
X_test=as.matrix(cv_data[[4]][[i]][j])
Y_test=as.matrix(cv_data[[4]][[i]][6])
Ksvm=ksvm(y=as.factor(Y_train),x=X_train,
kernel='vanilladot',scaled=FALSE,C=1)
pred<-predict(Ksvm,X_test)
Table=table(pred,Y_test)
Accuracy=(Table[1,1]+Table[2,2])/sum(Table)
Precision=Table[2,2]/(Table[2,1]+Table[2,2])
Recall=Table[2,2]/(Table[1,2]+Table[2,2])
aux<-cbind(nombres[j],i,Accuracy,Precision,Recall)
aux_2<-rbind(aux_2,aux)
lista[[length(lista)+1]]=aux
}
resultados<-cbind("Covariable","Fold","Accuracy","Precision","Recall")
resultados<-rbind(resultados,aux_2)
return(resultados)
}
for (j in 1:5){
nombres<-colnames(cv_data[[3]][[1]])
aux<-c()
for (i in 1:5){
#Entrenamiento
X_train=as.matrix(cv_data[[3]][[i]][j])
Y_train=as.matrix(cv_data[[3]][[i]][6])
#Testeo
X_test=as.matrix(cv_data[[4]][[i]][j])
Y_test=as.matrix(cv_data[[4]][[i]][6])
Ksvm=ksvm(y=as.factor(Y_train),x=X_train,
kernel='vanilladot',scaled=FALSE,C=1)
pred<-predict(Ksvm,X_test)
Table=table(pred,Y_test)
Accuracy=(Table[1,1]+Table[2,2])/sum(Table)
Precision=Table[2,2]/(Table[2,1]+Table[2,2])
Recall=Table[2,2]/(Table[1,2]+Table[2,2])
aux<-cbind(nombres[j],i,Accuracy,Precision,Recall)
aux_2<-rbind(aux_2,aux)
lista[[length(lista)+1]]=aux
}
resultados<-cbind("Covariable","Fold","Accuracy","Precision","Recall")
resultados<-rbind(resultados,aux_2)
}
for (j in 1:5){
nombres<-colnames(cv_data[[3]][[1]])
aux_2<-c()
for (i in 1:5){
aux<-c()
#Entrenamiento
X_train=as.matrix(cv_data[[3]][[i]][j])
Y_train=as.matrix(cv_data[[3]][[i]][6])
#Testeo
X_test=as.matrix(cv_data[[4]][[i]][j])
Y_test=as.matrix(cv_data[[4]][[i]][6])
Ksvm=ksvm(y=as.factor(Y_train),x=X_train,
kernel='vanilladot',scaled=FALSE,C=1)
pred<-predict(Ksvm,X_test)
Table=table(pred,Y_test)
Accuracy=(Table[1,1]+Table[2,2])/sum(Table)
Precision=Table[2,2]/(Table[2,1]+Table[2,2])
Recall=Table[2,2]/(Table[1,2]+Table[2,2])
aux<-cbind(nombres[j],i,Accuracy,Precision,Recall)
aux_2<-rbind(aux_2,aux)
lista[[length(lista)+1]]=aux
}
resultados<-cbind("Covariable","Fold","Accuracy","Precision","Recall")
resultados<-rbind(resultados,aux_2)
}
View(resultados)
resultados<-cbind("Covariable","Fold","Accuracy","Precision","Recall")
for (j in 1:5){
nombres<-colnames(cv_data[[3]][[1]])
aux_2<-c()
for (i in 1:5){
aux<-c()
#Entrenamiento
X_train=as.matrix(cv_data[[3]][[i]][j])
Y_train=as.matrix(cv_data[[3]][[i]][6])
#Testeo
X_test=as.matrix(cv_data[[4]][[i]][j])
Y_test=as.matrix(cv_data[[4]][[i]][6])
Ksvm=ksvm(y=as.factor(Y_train),x=X_train,
kernel='vanilladot',scaled=FALSE,C=1)
pred<-predict(Ksvm,X_test)
Table=table(pred,Y_test)
Accuracy=(Table[1,1]+Table[2,2])/sum(Table)
Precision=Table[2,2]/(Table[2,1]+Table[2,2])
Recall=Table[2,2]/(Table[1,2]+Table[2,2])
aux<-cbind(nombres[j],i,Accuracy,Precision,Recall)
aux_2<-rbind(aux_2,aux)
lista[[length(lista)+1]]=aux
}
resultados<-rbind(resultados,aux_2)
}
View(resultados)
resultados<-c("Covariable","Fold","Accuracy","Precision","Recall")
for (j in 1:5){
nombres<-colnames(cv_data[[3]][[1]])
aux_2<-c()
for (i in 1:5){
aux<-c()
#Entrenamiento
X_train=as.matrix(cv_data[[3]][[i]][j])
Y_train=as.matrix(cv_data[[3]][[i]][6])
#Testeo
X_test=as.matrix(cv_data[[4]][[i]][j])
Y_test=as.matrix(cv_data[[4]][[i]][6])
Ksvm=ksvm(y=as.factor(Y_train),x=X_train,
kernel='vanilladot',scaled=FALSE,C=1)
pred<-predict(Ksvm,X_test)
Table=table(pred,Y_test)
Accuracy=(Table[1,1]+Table[2,2])/sum(Table)
Precision=Table[2,2]/(Table[2,1]+Table[2,2])
Recall=Table[2,2]/(Table[1,2]+Table[2,2])
aux<-cbind(nombres[j],i,Accuracy,Precision,Recall)
aux_2<-rbind(aux_2,aux)
lista[[length(lista)+1]]=aux
}
resultados<-rbind(resultados,aux_2)
}
resultados<-cbind("Covariable","Fold","Accuracy","Precision","Recall")
for (j in 1:5){
nombres<-colnames(cv_data[[3]][[1]])
aux_2<-c()
for (i in 1:5){
aux<-c()
#Entrenamiento
X_train=as.matrix(cv_data[[3]][[i]][j])
Y_train=as.matrix(cv_data[[3]][[i]][6])
#Testeo
X_test=as.matrix(cv_data[[4]][[i]][j])
Y_test=as.matrix(cv_data[[4]][[i]][6])
Ksvm=ksvm(y=as.factor(Y_train),x=X_train,
kernel='vanilladot',scaled=FALSE,C=1)
pred<-predict(Ksvm,X_test)
Table=table(pred,Y_test)
Accuracy=(Table[1,1]+Table[2,2])/sum(Table)
Precision=Table[2,2]/(Table[2,1]+Table[2,2])
Recall=Table[2,2]/(Table[1,2]+Table[2,2])
aux<-cbind(nombres[j],i,Accuracy,Precision,Recall)
aux_2<-rbind(aux_2,aux)
lista[[length(lista)+1]]=aux
}
resultados<-rbind(resultados,aux_2)
}
View(resultados)
resultados<-c()
for (j in 1:5){
nombres<-colnames(cv_data[[3]][[1]])
aux_2<-c()
for (i in 1:5){
aux<-c()
#Entrenamiento
X_train=as.matrix(cv_data[[3]][[i]][j])
Y_train=as.matrix(cv_data[[3]][[i]][6])
#Testeo
X_test=as.matrix(cv_data[[4]][[i]][j])
Y_test=as.matrix(cv_data[[4]][[i]][6])
Ksvm=ksvm(y=as.factor(Y_train),x=X_train,
kernel='vanilladot',scaled=FALSE,C=1)
pred<-predict(Ksvm,X_test)
Table=table(pred,Y_test)
Accuracy=(Table[1,1]+Table[2,2])/sum(Table)
Precision=Table[2,2]/(Table[2,1]+Table[2,2])
Recall=Table[2,2]/(Table[1,2]+Table[2,2])
aux<-cbind(nombres[j],i,Accuracy,Precision,Recall)
aux_2<-rbind(aux_2,aux)
lista[[length(lista)+1]]=aux
}
resultados<-rbind(resultados,aux_2)
}
View(resultados)
library("kernlab")
library(openintro)
pacman::p_load(tidyverse, tidymodels)
library("kernlab")
library(openintro)
data(starbucks)
attach(starbucks)
summary(starbucks)
data<-starbucks
data$type<- ifelse(data$type == 'bakery', 1, 0)
# Y=data$type
# data$type<-NULL
data$item<-NULL
# X=as.matrix(data)
# Prepare the data frame containing the cross validation partitions
folds <- vfold_cv(data, v = 5, strata = "type" )
folds
cv_data <- folds %>%
mutate(
# Extract the train data frame for each split
train = map(splits, ~training(.x)),
# Extract the validate data frame for each split
validate = map(splits, ~testing(.x))
)
resultados
resultados
resultados
resultados<-c()
for (j in 1:5){
nombres<-colnames(cv_data[[3]][[1]])
aux_2<-c()
for (i in 1:5){
aux<-c()
#Entrenamiento
X_train=as.matrix(cv_data[[3]][[i]][j])
Y_train=as.matrix(cv_data[[3]][[i]][6])
#Testeo
X_test=as.matrix(cv_data[[4]][[i]][j])
Y_test=as.matrix(cv_data[[4]][[i]][6])
Ksvm=ksvm(y=as.factor(Y_train),x=X_train,
kernel='vanilladot',scaled=FALSE,C=1)
pred<-predict(Ksvm,X_test)
Table=table(pred,Y_test)
Accuracy=(Table[1,1]+Table[2,2])/sum(Table)
Precision=Table[2,2]/(Table[2,1]+Table[2,2])
Recall=Table[2,2]/(Table[1,2]+Table[2,2])
aux<-cbind(nombres[j],i,Accuracy,Precision,Recall)
aux_2<-rbind(aux_2,aux)
lista[[length(lista)+1]]=aux
}
resultados<-rbind(resultados,aux_2)
}
resultados<-c()
for (j in 1:5){
nombres<-colnames(cv_data[[3]][[1]])
aux_2<-c()
for (i in 1:5){
aux<-c()
#Entrenamiento
X_train=as.matrix(cv_data[[3]][[i]][j])
Y_train=as.matrix(cv_data[[3]][[i]][6])
#Testeo
X_test=as.matrix(cv_data[[4]][[i]][j])
Y_test=as.matrix(cv_data[[4]][[i]][6])
Ksvm=ksvm(y=as.factor(Y_train),x=X_train,
kernel='vanilladot',scaled=FALSE,C=1)
pred<-predict(Ksvm,X_test)
Table=table(pred,Y_test)
Accuracy=(Table[1,1]+Table[2,2])/sum(Table)
Precision=Table[2,2]/(Table[2,1]+Table[2,2])
Recall=Table[2,2]/(Table[1,2]+Table[2,2])
aux<-cbind(nombres[j],i,Accuracy,Precision,Recall)
aux_2<-rbind(aux_2,aux)
}
resultados<-rbind(resultados,aux_2)
}
resultados
View(resultados)
medias<-resultados %>%  group_by(V1) %>%
+   summarise(Accuracy = mean(Accuracy), Precision = mean(Precision), Recall = mean(Recall))
medias<-resultados %>%  group_by(V1) %>%
summarise(Accuracy = mean(Accuracy), Precision = mean(Precision), Recall = mean(Recall))
resultados<-data.frame(resultados)
View(resultados)
medias<-resultados %>%  group_by(V1) %>%
summarise(Accuracy = mean(Accuracy), Precision = mean(Precision), Recall = mean(Recall))
View(medias)
medias<-resultados %>%  group_by(V1) %>%
+summarise(Accuracy = mean(Accuracy), Precision = mean(Precision), Recall = mean(Recall))
medias<-resultados %>%  group_by(V1) %>%
+summarise(A = mean(Accuracy), P = mean(Precision), R = mean(Recall))
medias<-resultados %>%  group_by(V1) %>% summarise(A = mean(Accuracy), P = mean(Precision), R = mean(Recall))
medias<-(resultados %>%  group_by(V1)) %>% summarise(A = mean(Accuracy), P = mean(Precision), R = mean(Recall))
medias<-(resultados %>%  group_by(V1)) %>% summarise(A = mean(Accuracy), P = mean(Precision), R = mean(Recall))
View(medias)
resumen<-resultados %>%  group_by(V1)
View(resumen)
medias<-resumen %>% summarise(A = mean(Accuracy), P = mean(Precision), R = mean(Recall))
View(medias)
View(resumen)
resumen<-
medias<- >resultados %>%  group_by(V1) %>% summarise(A = mean(Accuracy), P = mean(Precision), R = mean(Recall))
resumen<-
resultados %>%  group_by(V1) %>% summarise(A = mean(Accuracy), P = mean(Precision), R = mean(Recall))
View(medias)
View(resumen)
resultados %>%  group_by(V1) %>% summarise(A = mean(Accuracy), P = mean(Precision), R = mean(Recall))
warnings()
resultados<-c()
for (j in 1:5){
nombres<-colnames(cv_data[[3]][[1]])
aux_2<-c()
for (i in 1:5){
aux<-c()
#Entrenamiento
X_train=as.matrix(cv_data[[3]][[i]][j])
Y_train=as.matrix(cv_data[[3]][[i]][6])
#Testeo
X_test=as.matrix(cv_data[[4]][[i]][j])
Y_test=as.matrix(cv_data[[4]][[i]][6])
Ksvm=ksvm(y=as.factor(Y_train),x=X_train,
kernel='vanilladot',scaled=FALSE,C=1)
pred<-predict(Ksvm,X_test)
Table=table(pred,Y_test)
Accuracy=(Table[1,1]+Table[2,2])/sum(Table)
Precision=Table[2,2]/(Table[2,1]+Table[2,2])
Recall=Table[2,2]/(Table[1,2]+Table[2,2])
aux<-cbind(nombres[j],i,as.numeric(Accuracy),as.numeric(Precision),as.numeric(Recall))
aux_2<-rbind(aux_2,aux)
}
resultados<-rbind(resultados,aux_2)
}
resultados<-data.frame(resultados)
resultados %>%  group_by(V1) %>% summarise(A = mean(Accuracy), P = mean(Precision), R = mean(Recall))
View(resultados)
medias<-resultados %>%  group_by(V1) %>% summarise(Accuracy = mean(V3), Precision = mean(V4), Recall = mean(V5))
View(medias)
str(resultados)
resultados<-data.frame(resultados, colnames=c("Covariable", "Kfold", "Accuracy", "Precision", "Recall"))
str(resultados)
resultados<-data.frame(resultados, names=c("Covariable", "Kfold", "Accuracy", "Precision", "Recall"))
str(resultados)
?data.frame
resultados<-c()
for (j in 1:5){
nombres<-colnames(cv_data[[3]][[1]])
aux_2<-c()
for (i in 1:5){
aux<-c()
#Entrenamiento
X_train=as.matrix(cv_data[[3]][[i]][j])
Y_train=as.matrix(cv_data[[3]][[i]][6])
#Testeo
X_test=as.matrix(cv_data[[4]][[i]][j])
Y_test=as.matrix(cv_data[[4]][[i]][6])
Ksvm=ksvm(y=as.factor(Y_train),x=X_train,
kernel='vanilladot',scaled=FALSE,C=1)
pred<-predict(Ksvm,X_test)
Table=table(pred,Y_test)
Accuracy=(Table[1,1]+Table[2,2])/sum(Table)
Precision=Table[2,2]/(Table[2,1]+Table[2,2])
Recall=Table[2,2]/(Table[1,2]+Table[2,2])
aux<-cbind(nombres[j],i,Accuracy,Precision,Recall)
aux_2<-rbind(aux_2,aux)
}
resultados<-rbind(resultados,aux_2)
}
#resultados generales.
resultados<-data.frame(resultados)
colnames(resultados)<-c("Covariable", "Kfold", "Accuracy", "Precision", "Recall")
View(resultados)
resultados<-resultados %>% mutate(Accuracy=as.numeric(Accuracy))
str(resultados)
resultados<-resultados %>% mutate(Accuracy=as.numeric(Accuracy),
Precision=as.numeric(Precision),
Recall=as.numeric(Recall))
str(resultados)
medias<-resultados %>%  group_by(V1) %>% summarise(Accuracy = mean(V3), Precision = mean(V4), Recall = mean(V5))
medias<-resultados %>%  group_by(V1) %>% summarise(Accuracy = mean(Accuracy),
Precision = mean(Precision),
Recall = mean(Recall))
medias<-resultados %>%  group_by(Covariable) %>% summarise(Accuracy = mean(Accuracy),
Precision = mean(Precision),
Recall = mean(Recall))
View(medias)
pacman::p_load(tidyverse, tidymodels)
library("kernlab")
library(openintro)
data(starbucks)
attach(starbucks)
summary(starbucks)
data<-starbucks
data$type<- ifelse(data$type == 'bakery', 1, 0)
# Y=data$type
# data$type<-NULL
data$item<-NULL
# X=as.matrix(data)
# Prepare the data frame containing the cross validation partitions
folds <- vfold_cv(data, v = 5, strata = "type" )
folds
cv_data <- folds %>%
mutate(
# Extract the train data frame for each split
train = map(splits, ~training(.x)),
# Extract the validate data frame for each split
validate = map(splits, ~testing(.x))
)
#3 es train
# cv_data[[3]][[1]][1:5]
# #4 es test
#
# Y=as.matrix(cv_data[[3]][[1]][6])
# X=as.matrix(cv_data[[3]][[1]][1:5])
resultados<-c()
for (j in 1:5){
nombres<-colnames(cv_data[[3]][[1]])
aux_2<-c()
for (i in 1:5){
aux<-c()
#Entrenamiento
X_train=as.matrix(cv_data[[3]][[i]][j])
Y_train=as.matrix(cv_data[[3]][[i]][6])
#Testeo
X_test=as.matrix(cv_data[[4]][[i]][j])
Y_test=as.matrix(cv_data[[4]][[i]][6])
Ksvm=ksvm(y=as.factor(Y_train),x=X_train,
kernel='vanilladot',scaled=FALSE,C=1)
pred<-predict(Ksvm,X_test)
Table=table(pred,Y_test)
Accuracy=(Table[1,1]+Table[2,2])/sum(Table)
Precision=Table[2,2]/(Table[2,1]+Table[2,2])
Recall=Table[2,2]/(Table[1,2]+Table[2,2])
aux<-cbind(nombres[j],i,Accuracy,Precision,Recall)
aux_2<-rbind(aux_2,aux)
}
resultados<-rbind(resultados,aux_2)
}
#resultados generales.
resultados<-data.frame(resultados)
colnames(resultados)<-c("Covariable", "Kfold", "Accuracy", "Precision", "Recall")
resultados<-resultados %>% mutate(Accuracy=as.numeric(Accuracy),
Precision=as.numeric(Precision),
Recall=as.numeric(Recall))
str(resultados)
medias<-resultados %>%  group_by(Covariable) %>% summarise(Accuracy = mean(Accuracy),
Precision = mean(Precision),
Recall = mean(Recall))
medias
View(resultados)
