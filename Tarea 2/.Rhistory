et.seed(201207)
set.seed(201207)
#Generamos los datos
n = 40 #Tamaño de la muestra
x = sort(runif(n, 0,5))
y = sin(x)+x^(1/3)-0.1+rnorm(n,0,1/5)
plot(x,y)
n=length(x)
p=0.3
index=sample(1:n,floor(p*n),replace=FALSE)
xtest=x[index]
ytest=y[index]
xtrain=x[-index]
ytrain=y[-index]
##Paso 2: estandarizar
mux=mean(xtrain)
sdx=sd(xtrain)
xtrain_est=(xtrain-mux)/sdx
xtest_est=(xtest-mux)/sdx
##Paso 3: Definir una funcion de kernel
Kfun=function(xi,xj,l2=0.05)
{
exp(-sum((xi-xj)^2)/l2)
}
ntrain=length(xtrain_est)
rm(list = ls())
set.seed(23)
path = '~/OneDrive - Universidad Adolfo Ibanez/Codes/Universidad/Kernels/Repo/Tarea 2/sim.txt'
data = read.delim(path, header = TRUE, sep = ",", dec = ".")
index <- sample(1:4, 200, replace=TRUE)
data['grupo'] <- index
train <- data[which(data$grupo == 1 | data$grupo == 2 | data$grupo == 3),]
test <- data[which(data$grupo == 4),]
x1_train = train[1]
x2_train = train[2]
y_train = train[3]
x1_test = test[1]
x2_test = test[2]
y_test = test[3]
mux1 = mean(x1_train)
sdx1 = sd(x1_train)
mux2 = mean(x2_train)
sdx2 = sd(x2_train)
x1train_est = (x1_train - mux1)/sdx1
x1test_est = (x1_test - mux1)/sdx1
x2train_est = (x2_train - mux2)/sdx2
x2test_est = (x2_test - mux2)/sdx2
Kfun = function(xi,xj,l2=0.5)
{
exp(-sum((xi-xj)^2)/l2)
}
x1train_est[1]
x1train_est = (x1_train - mux1)/sdx1
mux1 = mean(x1_train)
sdx1 = sd(x1_train)
mux2 = mean(x2_train)
source("~/Library/CloudStorage/OneDrive-UniversidadAdolfoIbanez/Codes/Universidad/Kernels/Repo/Tarea 2/T2Kernels.R", echo=TRUE)
set.seed(201207)
#Generamos los datos
n = 40 #Tamaño de la muestra
x = sort(runif(n, 0,5))
y = sin(x)+x^(1/3)-0.1+rnorm(n,0,1/5)
plot(x,y)
##Paso 1: dividimos en set de entrenamiento y testeo
n=length(x)
p=0.3
index=sample(1:n,floor(p*n),replace=FALSE)
xtest=x[index]
ytest=y[index]
xtrain=x[-index]
ytrain=y[-index]
##Paso 2: estandarizar
mux=mean(xtrain)
sdx=sd(xtrain)
xtrain_est=(xtrain-mux)/sdx
xtest_est=(xtest-mux)/sdx
##Paso 3: Definir una funcion de kernel
Kfun=function(xi,xj,l2=0.05)
{
exp(-sum((xi-xj)^2)/l2)
}
##Paso 4: Calculamos la matriz Gram
ntrain=length(xtrain_est)
K=matrix(0,nrow=ntrain,ncol=ntrain)
xtrain_est[1]
x1train_est[2]
xtrain_est[2]
rm(list = ls())
source("~/Library/CloudStorage/OneDrive-UniversidadAdolfoIbanez/Codes/Universidad/Kernels/Repo/Tarea 2/T2Kernels.R", echo=TRUE)
set.seed(201207)
#Generamos los datos
n = 40 #Tamaño de la muestra
x = sort(runif(n, 0,5))
y = sin(x)+x^(1/3)-0.1+rnorm(n,0,1/5)
plot(x,y)
##Paso 1: dividimos en set de entrenamiento y testeo
n=length(x)
p=0.3
index=sample(1:n,floor(p*n),replace=FALSE)
xtest=x[index]
ytest=y[index]
xtrain=x[-index]
ytrain=y[-index]
##Paso 2: estandarizar
mux=mean(xtrain)
sdx=sd(xtrain)
source("~/Library/CloudStorage/OneDrive-UniversidadAdolfoIbanez/Codes/Universidad/Kernels/Repo/Tarea 2/T2Kernels.R", echo=TRUE)
x1_train[:]
x1_train[]
x1_train
type(x1_train)
typeof(x1_train)
source("~/Library/CloudStorage/OneDrive-UniversidadAdolfoIbanez/Codes/Universidad/Kernels/Repo/Tarea 2/T2Kernels.R", echo=TRUE)
source("~/Library/CloudStorage/OneDrive-UniversidadAdolfoIbanez/Codes/Universidad/Kernels/Repo/Tarea 2/T2Kernels.R", echo=TRUE)
View(data)
